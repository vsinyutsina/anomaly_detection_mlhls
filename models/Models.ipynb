{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from category_encoders.one_hot import OneHotEncoder \n",
        "\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "VYtYssAJgWA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle\n",
        "!touch ~/.kaggle/kaggle.json\n",
        "\n",
        "api_token = {\"username\":\"\",\n",
        "             \"key\":\"\"}\n",
        "\n",
        "import json\n",
        "\n",
        "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(api_token, file)\n",
        "\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "import kaggle\n",
        "\n",
        "!kaggle competitions download -c ieee-fraud-detection\n",
        "\n",
        "!unzip ieee-fraud-detection"
      ],
      "metadata": {
        "id": "aD0Fy11U_ejh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_identity = pd.read_csv('train_identity.csv')\n",
        "train_transaction = pd.read_csv('train_transaction.csv')\n",
        "train_transaction.isFraud = train_transaction.isFraud.astype('str')\n",
        "\n",
        "test_identity = pd.read_csv('test_identity.csv')\n",
        "test_transaction = pd.read_csv('test_transaction.csv')"
      ],
      "metadata": {
        "id": "Ksh30rXNY042"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# трейн\n",
        "X_train =  train_transaction.drop('isFraud', axis=1)\n",
        "X_train = X_train.merge(train_identity, how='outer', on='TransactionID')\n",
        "\n",
        "y_train = train_transaction['isFraud']\n",
        "\n",
        "# тест\n",
        "X_test = test_transaction.merge(test_identity, how='outer', on='TransactionID')"
      ],
      "metadata": {
        "id": "ysV2rxvsgTuv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# del train_transaction, train_identity, test_transaction, test_identity"
      ],
      "metadata": {
        "id": "5e4EEfR1KDrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Описание плана\n",
        "* Сделать предобработку признаков, оставить только самые полезные\n",
        "* Для линейных моделей выкидываем коррелирующие признаки\n",
        "* Бейзлайн - предсказываем мажоритарный класс\n",
        "* Обучить логистическую регресию с L1 регуляризацией и посмотреть у каких признаков нулевые веса\n",
        "* Накладывать на линейную фкнкцию после зануления весов более сложные конструкции признаки могут выстрелить в бустинге, но не могут выстрелить в регрессии\n",
        "* взять подвыборку 70к и понизить размерность до 2х T-SNE/PCA, сдлеать скеттер плот и выделить фрод не фрод показывает возможность классификации\n",
        "\n",
        "\n",
        "## Признаки\n",
        "\n",
        "На основе EDA мы выделили для себя следующие полезные признаки"
      ],
      "metadata": {
        "id": "f6rJ8cCCjQjM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "v_cols = ['V166', 'V77', 'V305', 'V47', 'V240', \n",
        "     'V241', 'V120', 'V171', 'V3', 'V56', \n",
        "     'V107', 'V260', 'V109', 'V282', \n",
        "     'V7', 'V124', 'V46', 'V115', 'V1', \n",
        "     'V6', 'V220', 'V283', 'V281', 'V209', \n",
        "     'V173', 'V223', 'V78', 'V118', 'V121', \n",
        "     'V210', 'V2', 'V174', 'V226', 'V169', \n",
        "     'V122', 'V286', 'V55', 'V138', 'V208', \n",
        "     'V329', 'V273', 'V42', 'V52', 'V265', \n",
        "     'V266', 'V229', 'V276', 'V235', 'V186',\n",
        "     'V91', 'V234', 'V338', 'V158', 'V326', \n",
        "     'V259', 'V246', 'V160', 'V187', 'V303', \n",
        "     'V268', 'V89', 'V41', 'V247', 'V195',\n",
        "     'V325', 'V315', 'V292', 'V272', 'V201', \n",
        "     'V163', 'V137', 'V130', 'V113', 'V9', \n",
        "     'V87', 'V83', 'V76', 'V67', 'V62', \n",
        "     'V54', 'V5', 'V45', 'V38', 'V36', \n",
        "     'V301', 'V289', 'V262', 'V26', 'V251', \n",
        "     'V24', 'V239', 'V20', 'V188', 'V185', \n",
        "     'V175', 'V170', 'V147', 'V142', \n",
        "     'V140', 'V13', 'V125', 'V119', 'V116', 'V110']"
      ],
      "metadata": {
        "id": "kIB2PZuj-l2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols_float = ['TransactionDT', 'TransactionAmt', \n",
        "              'addr1', 'addr2',\n",
        "              'dist1', 'dist2', \n",
        "              'card1', 'card2', 'card3', 'card5',\n",
        "              'C1', 'C3', 'C5', 'C9', 'C13',\n",
        "              'D1','D7', 'D8', 'D9', 'D10', 'D11', 'D12']\n",
        "cols_float.extend(v_cols)\n",
        "\n",
        "\n",
        "cols_cat = ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain',\n",
        "            'DeviceType', 'DeviceInfo']\n",
        "cols_cat.extend(['M' + str(i) for i in range(1, 10)])"
      ],
      "metadata": {
        "id": "eoFV4PG65esc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train[cols_float + cols_cat]\n",
        "X_test = X_test[cols_float + cols_cat]"
      ],
      "metadata": {
        "id": "Le7Noc3bLGF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Заполним пропуски"
      ],
      "metadata": {
        "id": "c0pTEm4wAcf5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in cols_float:\n",
        "  X_train.loc[X_train[col].isna(), col] = X_train[col].mean()\n",
        "  X_test.loc[X_test[col].isna(), col] = X_test[col].mean()\n",
        "\n",
        "\n",
        "for col in cols_cat:\n",
        "  X_train.loc[X_train[col].isna(), col] = 'no_' + col\n",
        "  X_test.loc[X_test[col].isna(), col] = 'no_' + col "
      ],
      "metadata": {
        "id": "vp1QA0VP5exS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Подкинем пару новых признаков"
      ],
      "metadata": {
        "id": "oglsslf2H3fr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train['TransactionAmt_cents'] = X_train['TransactionAmt'].astype('str').str.split('.').apply(lambda x: x[1])\n",
        "X_train['TransactionAmt_int_sum'] = X_train['TransactionAmt'].astype('str').str.split('.').apply(lambda x: x[0])\n",
        "\n",
        "X_test['TransactionAmt_cents'] = X_test['TransactionAmt'].astype('str').str.split('.').apply(lambda x: x[1])\n",
        "X_test['TransactionAmt_int_sum'] = X_test['TransactionAmt'].astype('str').str.split('.').apply(lambda x: x[0])"
      ],
      "metadata": {
        "id": "uj3Rt20_Fpi5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols_float.extend(['TransactionAmt_cents', 'TransactionAmt_int_sum'])"
      ],
      "metadata": {
        "id": "Rp4je3rQHHqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dttm(date):\n",
        "    date = date - 86400\n",
        "    return (date // 86400 // 7,\n",
        "        date // 86400 % 7, \n",
        "        date % 86400 // 3600,\n",
        "        date % 86400 % 3600 // 60,\n",
        "        date % 86400 % 3600 % 60)\n",
        "\n",
        "\n",
        "X_train['dttm_week'] = X_train.TransactionDT.apply(dttm).apply(lambda x: x[0])\n",
        "X_train['dttm_day'] = X_train.TransactionDT.apply(dttm).apply(lambda x: x[1])\n",
        "X_train['dttm_hour'] = X_train.TransactionDT.apply(dttm).apply(lambda x: x[2])\n",
        "X_train['dttm_minute'] = X_train.TransactionDT.apply(dttm).apply(lambda x: x[3])\n",
        "X_train['dttm_sec'] = X_train.TransactionDT.apply(dttm).apply(lambda x: x[4])\n",
        "\n",
        "X_test['dttm_week'] = X_test.TransactionDT.apply(dttm).apply(lambda x: x[0])\n",
        "X_test['dttm_day'] = X_test.TransactionDT.apply(dttm).apply(lambda x: x[1])\n",
        "X_test['dttm_hour'] = X_test.TransactionDT.apply(dttm).apply(lambda x: x[2])\n",
        "X_test['dttm_minute'] = X_test.TransactionDT.apply(dttm).apply(lambda x: x[3])\n",
        "X_test['dttm_sec'] = X_test.TransactionDT.apply(dttm).apply(lambda x: x[4])"
      ],
      "metadata": {
        "id": "Sdz8b1lvH6a8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols_float.extend(['dttm_week', 'dttm_day', 'dttm_hour', 'dttm_minute', 'dttm_sec'])"
      ],
      "metadata": {
        "id": "WOhFW5CsIpuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "deviceinfo_most_pop = X_train.query('DeviceInfo != \"no_DeviceInfo\"')['DeviceInfo']\\\n",
        "                                                                              .value_counts()\\\n",
        "                                                                              .head(5)\\\n",
        "                                                                              .index\\\n",
        "                                                                              .tolist()\n",
        "deviceinfo_most_pop.append('no_DeviceInfo')\n",
        "\n",
        "X_train.loc[:, 'DeviceInfo'] = X_train['DeviceInfo'].apply(lambda x: x if x in deviceinfo_most_pop else 'other')\n",
        "X_test.loc[:, 'DeviceInfo'] = X_test['DeviceInfo'].apply(lambda x: x if x in deviceinfo_most_pop else 'other')"
      ],
      "metadata": {
        "id": "wXRI8c_3VRon"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Нормализуем вещественные признаки"
      ],
      "metadata": {
        "id": "1AWbVNbHCT5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "standard_scaler = StandardScaler(copy=True)\n",
        "\n",
        "for col in cols_float[:-7]:\n",
        "  if X_train[X_train[col] < 0].shape[0]:\n",
        "    continue\n",
        "\n",
        "  X_train[col] = np.log(X_train[col])\n",
        "  X_test[col] = np.log(X_test[col])\n",
        "\n",
        "X_train[cols_float] = X_train[cols_float].replace(np.inf * -1, -1000000000)\n",
        "X_test[cols_float] = X_test[cols_float].replace(np.inf * -1, -1000000000)\n",
        "\n",
        "X_train[cols_float] = X_train[cols_float].replace(np.inf, 1000000000)\n",
        "X_test[cols_float] = X_test[cols_float].replace(np.inf, 1000000000)\n",
        "\n",
        "X_train_matrix = standard_scaler.fit_transform(X_train[cols_float])\n",
        "X_test_matrix = standard_scaler.transform(X_test[cols_float])"
      ],
      "metadata": {
        "id": "5Ihwman-5e9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in cols_float:\n",
        "  na_percent = X_train[X_train[col].isna()].shape[0]/X_train.shape[0] * 100\n",
        "  if na_percent > 0:\n",
        "    print(col, na_percent)"
      ],
      "metadata": {
        "id": "Egy8d4R8dXsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_matrix = pd.DataFrame(X_train_matrix) \n",
        "X_train_matrix.columns = X_train[cols_float].columns\n",
        "\n",
        "X_test_matrix = pd.DataFrame(X_test_matrix) \n",
        "X_test_matrix.columns = X_test[cols_float].columns"
      ],
      "metadata": {
        "id": "LJwDcvZvEisZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train_matrix.to_csv('X_train_matrix.csv') \n",
        "# X_test_matrix.to_csv('X_test_matrix.csv') "
      ],
      "metadata": {
        "id": "jiiXvdd9L7ZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !zip X_train_matrix.zip X_train_matrix.csv\n",
        "# !zip X_test_matrix.zip X_test_matrix.csv"
      ],
      "metadata": {
        "id": "d7cmerXLMDJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "\n",
        "# files.download('X_train_matrix.zip')\n",
        "# files.download('X_test_matrix.zip')"
      ],
      "metadata": {
        "id": "GCtEeM3IMRJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Кодируем категориальные признаки"
      ],
      "metadata": {
        "id": "xnmjn7UNC6F5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for col in cols_cat:\n",
        "  print(col, X_train[col].nunique())"
      ],
      "metadata": {
        "id": "bvged-XBYUpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ohe_enc = OneHotEncoder()\n",
        "\n",
        "X_train_matrix_cat = ohe_enc.fit_transform(X_train[cols_cat])\n",
        "X_test_matrix_cat = ohe_enc.transform(X_test[cols_cat])"
      ],
      "metadata": {
        "id": "oj1OCfN-5fAG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_matrix_cat = pd.DataFrame(X_train_matrix_cat) \n",
        "X_train_matrix_cat.columns = ohe_enc.get_feature_names()\n",
        "\n",
        "X_test_matrix_cat = pd.DataFrame(X_test_matrix_cat) \n",
        "X_test_matrix_cat.columns = ohe_enc.get_feature_names()"
      ],
      "metadata": {
        "id": "4PHlK2LI5fCp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pd.concat([X_train_matrix, X_train_matrix_cat], axis=1)\n",
        "X_test = pd.concat([X_test_matrix, X_test_matrix_cat], axis=1)"
      ],
      "metadata": {
        "id": "cPrwWfOr5fEu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert X_test.shape[1] == X_train.shape[1]"
      ],
      "metadata": {
        "id": "vke1hLZXPtcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Log Reg с L2 регуляризацией"
      ],
      "metadata": {
        "id": "2oSUhIYHaKBO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# разделим данные на обучающую и тестовую выборки\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, train_size=0.7)"
      ],
      "metadata": {
        "id": "8pXkpc5mP0bx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# обучение логистической регрессии\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from tqdm import tqdm\n",
        "\n",
        "lr = LogisticRegression(max_iter=10000,\n",
        "                        warm_start=True)\n",
        "\n",
        "ran = np.arange(y_train.shape[0])\n",
        "inds = np.array_split(ran, 10)\n",
        "\n",
        "inds = [np.concatenate((chunk, np.array(random.sample(list(ran), k=100))), axis=None) for chunk in inds]\n",
        "\n",
        "for chunk in tqdm(inds):\n",
        "  lr.fit(X_train.iloc[chunk, :], y_train.iloc[chunk])"
      ],
      "metadata": {
        "id": "sM5H4zvRP2gE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_lr = lr.predict_proba(X_val)"
      ],
      "metadata": {
        "id": "sB9qQydRP5Tb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Посчитаем пороговое значение (если будет предсказывать мажоритарный класс)\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "benchmark = ['0' for _ in range(len(y_val))]\n",
        "\n",
        "roc_auc_score(y_val, benchmark)"
      ],
      "metadata": {
        "id": "_Q5CIKKYfCEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# посчитаем roc auc для обученого лог рега\n",
        "y_val_pred_for_fraud = [x[1] for x in pred_lr]\n",
        "\n",
        "roc_auc_score(y_val, y_val_pred_for_fraud)"
      ],
      "metadata": {
        "id": "aKcJ-mr0eWFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как минимум первая моделька уже неплохо обучилась и превысила пороговое значение. Мы уже немного молодцы)\n",
        "\n",
        "## Log Reg с l1-регуляризацией\n",
        "\n"
      ],
      "metadata": {
        "id": "5rhfKhuTl8Q3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression(max_iter=10000,\n",
        "                        warm_start=True,\n",
        "                        penalty='l1',\n",
        "                        solver='liblinear'\n",
        "                        )\n",
        "\n",
        "ran = np.arange(y_train.shape[0])\n",
        "inds = np.array_split(ran, 10)\n",
        "\n",
        "inds = [np.concatenate((chunk, np.array(random.sample(list(ran), k=100))), axis=None) for chunk in inds]\n",
        "\n",
        "for chunk in tqdm(inds):\n",
        "  lr.fit(X_train.iloc[chunk, :], y_train.iloc[chunk])"
      ],
      "metadata": {
        "id": "R6MLDr-ameFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_lr = lr.predict_proba(X_val)"
      ],
      "metadata": {
        "id": "YrBMYlctnvxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_val_pred_for_fraud = [x[1] for x in pred_lr]\n",
        "\n",
        "roc_auc_score(y_val, y_val_pred_for_fraud)"
      ],
      "metadata": {
        "id": "YGrW9TTpnzJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from datetime import datetime as dt\n",
        "\n",
        "model_name = f'best_model_{dt.today()}.pkl'\n",
        "with open(model_name, 'wb') as f:\n",
        "    pickle.dump(lr, f, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "79_nvqvvzMEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(model_name) "
      ],
      "metadata": {
        "id": "qHaq3vr8zUCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle \n",
        "\n",
        "with open('best_model_2022-12-23 16_38_11.565860.pkl', 'rb') as f:\n",
        "  lr = pickle.load(f)"
      ],
      "metadata": {
        "id": "4fJF4RnuQGCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "important_features = []\n",
        "for i, val in enumerate(lr.coef_[0]):\n",
        "  if val:\n",
        "    continue\n",
        "  important_features.append(i)"
      ],
      "metadata": {
        "id": "71Q5aLlUmeRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "important_cols = X_train.iloc[:, important_features].columns.tolist()"
      ],
      "metadata": {
        "id": "IOKf7jADoUg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Подбираем параметры для Log Reg"
      ],
      "metadata": {
        "id": "MkRH4vxurR9Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# C = [i/100 for i in range(1, 100, 10)]\n",
        "# C.extend([1, 3, 100])\n",
        "\n",
        "# for val in tqdm(C):\n",
        "\n",
        "#     lr = LogisticRegression(C=val, max_iter=500)\n",
        "#     lr.fit(X_train, y_train)\n",
        "\n",
        "#     pred_lr = lr.predict_proba(X_val)\n",
        "#     y_val_pred_for_fraud = [x[1] for x in pred_lr]\n",
        "#     print(val, roc_auc_score(y_val, y_val_pred_for_fraud))"
      ],
      "metadata": {
        "id": "JeQhf-TnrRCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr = LogisticRegression(max_iter=10000,\n",
        "                        warm_start=True,\n",
        "                        penalty='l1',\n",
        "                        solver='liblinear',\n",
        "                        C=3 #вроде как бест параметр\n",
        "                        )\n",
        "\n",
        "ran = np.arange(y_train.shape[0])\n",
        "inds = np.array_split(ran, 10)\n",
        "\n",
        "inds = [np.concatenate((chunk, np.array(random.sample(list(ran), k=100))), axis=None) for chunk in inds]\n",
        "\n",
        "for chunk in tqdm(inds):\n",
        "  lr.fit(X_train.iloc[chunk, :], y_train.iloc[chunk])"
      ],
      "metadata": {
        "id": "DGaq6doD-RIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_lr = lr.predict_proba(X_val)\n",
        "\n",
        "y_val_pred_for_fraud = [x[1] for x in pred_lr]\n",
        "\n",
        "roc_auc_score(y_val, y_val_pred_for_fraud)"
      ],
      "metadata": {
        "id": "I7o_Paty_-oR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from datetime import datetime as dt\n",
        "\n",
        "model_name = f'best_model_{dt.today()}.pkl'\n",
        "with open(model_name, 'wb') as f:\n",
        "    pickle.dump(lr, f, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "rSGbL4bIAtGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(model_name) "
      ],
      "metadata": {
        "id": "fGADpJTFAvPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SVM"
      ],
      "metadata": {
        "id": "YTh4SyTxo6PG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# очень долго обучается, поэтому решили попробовать снизить размерность данных \n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=2) # сократим кол-во признаков\n",
        "\n",
        "X_train_new = pca.fit_transform(X_train[important_cols])\n",
        "# X_val_new = pca.transform(X_val)\n",
        "# X_test_new = pca.transform(X_test)"
      ],
      "metadata": {
        "id": "gbaecFD2Ne_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "X_train_df = pd.DataFrame(X_train_new)\n",
        "sns.scatterplot(data=X_train_df, x=0, y=1, hue=y_train)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "U2Pr9bcrOchT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Визуально, на основе разложения, можно выделить два класса."
      ],
      "metadata": {
        "id": "IFbD2_R8RQXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# очень долго обучается, поэтому решили попробовать снизить размерность данных \n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=70) # сократим кол-во признаков\n",
        "\n",
        "X_train_new = pca.fit_transform(X_train[important_cols])\n",
        "X_val_new = pca.transform(X_val[important_cols])\n",
        "X_test_new = pca.transform(X_test[important_cols])"
      ],
      "metadata": {
        "id": "xWjWfSSM3n93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "for kernel in tqdm(['linear', 'rbf', 'poly', 'sigmoid']):\n",
        "    svm = SVC(kernel=kernel,\n",
        "              probability=True,\n",
        "              verbose=True,\n",
        "              max_iter=100)\n",
        "\n",
        "    svm.fit(X_train_new, y_train)\n",
        "\n",
        "    pred = svm.predict_proba(X_val_new)\n",
        "    y_val_pred_for_fraud = [x[1] for x in pred]\n",
        "\n",
        "    print(kernel, roc_auc_score(y_val, y_val_pred_for_fraud))"
      ],
      "metadata": {
        "id": "XKrxY-Pwo8YV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for degree in tqdm(np.arange(2,10)):\n",
        "    svm = SVC(kernel='linear', \n",
        "              degree=degree,\n",
        "              max_iter=1000)\n",
        "\n",
        "    svm.fit(X_train_new, y_train)\n",
        "\n",
        "    pred = svm.predict_proba(X_val_new)\n",
        "    y_val_pred_for_fraud = [x[1] for x in pred]\n",
        "\n",
        "    print(degree, roc_auc_score(y_val, y_val_pred_for_fraud))"
      ],
      "metadata": {
        "id": "FC1dYB8Mo8lQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "svm = SVC(kernel='linear',\n",
        "          max_iter=1000,\n",
        "          probability=True,\n",
        "          verbose=True)\n",
        "\n",
        "svm.fit(X_train, y_train)\n",
        "\n",
        "pred = svm.predict(X_val)\n",
        "\n",
        "print(degree, roc_auc_score(y_val, pred))"
      ],
      "metadata": {
        "id": "LSehiHwkJevh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from datetime import datetime as dt\n",
        "\n",
        "model_name = f'svm_best_model_{dt.today()}.pkl'\n",
        "with open(model_name, 'wb') as f:\n",
        "    pickle.dump(svm, f, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "DXGwgwYAKJfI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(model_name) "
      ],
      "metadata": {
        "id": "T93kSkymKPBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Catboost"
      ],
      "metadata": {
        "id": "9h7pZD7WUjLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostClassifier\n",
        "\n",
        "params = {\n",
        "    'iterations': 2500,\n",
        "    'depth': 8,\n",
        "    'loss_function' : 'Logloss',\n",
        "    'eval_metric' : 'AUC',\n",
        "    'learning_rate': .1,\n",
        "    'random_seed': 42,\n",
        "    'od_wait': 5,\n",
        "    'verbose': 100\n",
        "}\n",
        "\n",
        "model = CatBoostClassifier(**params)\n",
        "\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "us0cBRw8Uk8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict_proba(X_val)\n",
        "\n",
        "y_val_pred_for_fraud = [x[1] for x in pred]\n",
        "\n",
        "print(roc_auc_score(y_val, y_val_pred_for_fraud))"
      ],
      "metadata": {
        "id": "c6HEYS0hXqq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "from datetime import datetime as dt\n",
        "\n",
        "model_name = f'catboost_best_model_{dt.today()}.pkl'\n",
        "with open(model_name, 'wb') as f:\n",
        "    pickle.dump(model, f, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "metadata": {
        "id": "NnItr_vQYS2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download(model_name)"
      ],
      "metadata": {
        "id": "HKXMM25eZh1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Тестовый сабмит "
      ],
      "metadata": {
        "id": "QrF7lyGtme2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_lr = lr.predict_proba(X_test)"
      ],
      "metadata": {
        "id": "luXGSRd_gJdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = pd.read_csv('sample_submission.csv')\n",
        "sample.shape"
      ],
      "metadata": {
        "id": "rfa2yEFgfvWR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = model.predict_proba(X_test)"
      ],
      "metadata": {
        "id": "moTJ4jA5Yce6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = test_transaction['TransactionID'].reset_index()\n",
        "\n",
        "result['isFraud'] = [fraud for notfraud, fraud in pred]"
      ],
      "metadata": {
        "id": "NXeuPjd0f_2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cols = ['TransactionID','isFraud']\n",
        "result[cols].to_csv('prediction.csv', index=False)"
      ],
      "metadata": {
        "id": "wxBvYlUSjrqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions submit -c ieee-fraud-detection -f  prediction.csv -m \"Message\""
      ],
      "metadata": {
        "id": "h_yaNP_RYn_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VY7jyU6tauiw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}